{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanMusenga/TOSEM-2025-Submission/blob/main/GPT_4o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import all necessary modules or libraries"
      ],
      "metadata": {
        "id": "HbPYaTwo-WU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "0caaL8l_Rq8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=\"xxxxx\")\n",
        " # This is a free api key"
      ],
      "metadata": {
        "id": "JXUrrATKVEzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "8Goq3Kg2-TBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_excel(\"200_ARPs_and_Programming_Posts.xlsx\")"
      ],
      "metadata": {
        "id": "a8mb06UAkPur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to classify text using GPT-4o"
      ],
      "metadata": {
        "id": "4gEPqK3shHbV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP07xOHoRmMD"
      },
      "outputs": [],
      "source": [
        "# Create a valiable to store results\n",
        "result_gpt4 = []\n",
        "\n",
        "# Define a function to classify text using GPT-4o with retry logic by process each row\n",
        "def gpt4_classify(text, max_retries=5):\n",
        "    delay = 1  # Initialize delay before the loop\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create( # Use `client` instead of `openai.Chat.Completion.create`\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a classifier that determines whether a text is related to software architecture design. Reply with only “1” (architecture) or “0” (not architecture).\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Tell me if the following text is related to an architectural design discussion or software programming discussion. Just say 1 for  architectural design discussion or 0 for programming discussion.\\n\\n{text}\"}\n",
        "                ],\n",
        "                max_tokens=5,\n",
        "                temperature=0,\n",
        "            )\n",
        "            return response.choices[0].message.content.strip() #Correct way to access response. New OpenAI Python API (openai>=1.0.0) uses object attributes instead of dictionaries\n",
        "                                                           #(e.g., response[\"choices\"][0][\"message\"][\"content\"] ❌ is incorrect in the new version).\n",
        "\n",
        "        except openai.OpenAIError as e:  # Catch OpenAI API errors\n",
        "            print(f\"Error: {e}. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            delay *= 2  # Exponential backoff (1s → 2s → 4s → 8s → ...)\n",
        "\n",
        "    return None  # Return None if all retries fail\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process each row\n",
        "This process is very solow. It iterate each row in the dataset and that is it execute each row per second not a batch of posts and takes too much to finish"
      ],
      "metadata": {
        "id": "3MdcsYvykd3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variable to store predicted results\n",
        "result_gpt4 = []\n",
        "# Process each row\n",
        "for index, row in tqdm(dataset.iterrows(), total=dataset.shape[0]):\n",
        "    gpt_response = gpt4_classify(row['Question_body'])\n",
        "\n",
        "    if gpt_response is None:\n",
        "        result_gpt4.append(\"Error\")\n",
        "    else:\n",
        "        if \"Yes\" in gpt_response:\n",
        "            result_gpt4.append(1)\n",
        "        elif \"No\" in gpt_response:\n",
        "            result_gpt4.append(0)\n",
        "        else:\n",
        "            print(f\"Unexpected response: {gpt_response}\")\n",
        "            result_gpt4.append(\"Check Manually\")\n",
        "\n",
        "    time.sleep(1)  # Delay to avoid hitting rate limits\n",
        "\n",
        "\n",
        "#create a new row in dataset to store predicted values\n",
        "dataset[\"gpt4_pred\"] = result_gpt4"
      ],
      "metadata": {
        "id": "vkNhI9m9WxN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the updated dataset"
      ],
      "metadata": {
        "id": "lu155SQxhh1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated dataset\n",
        "dataset.to_excel(\"200_ARPs_and_Programming_Posts_with_predictions.xlsx\", index=False)\n",
        "print(\"Classification complete. Results saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mIHNGvXVjQy",
        "outputId": "8312ae9b-c63b-4515-ee08-28f4b25c15e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification complete. Results saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "PZu3gPpehlw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== Evaluation ========\n",
        "def scores(y_test, predictions):\n",
        "    precision = metrics.precision_score(y_test, predictions)\n",
        "    recall = metrics.recall_score(y_test, predictions)\n",
        "    f1 = metrics.f1_score(y_test, predictions)\n",
        "    acc = metrics.accuracy_score(y_test, predictions)\n",
        "\n",
        "\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-score: {f1}\")\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "\n",
        "# Ensure class labels exist in the dataset\n",
        "if \"Label\" in dataset.columns:\n",
        "    dataset = dataset.dropna(subset=[\"gpt4_pred\"])  # Remove NaN values\n",
        "    dataset[\"gpt4_pred\"] = dataset[\"gpt4_pred\"].astype(int)  # Convert to int\n",
        "\n",
        "    scores(dataset[\"Label\"], dataset[\"gpt4_pred\"])\n",
        "else:\n",
        "    print(\"Error: Column 'class' not found in dataset. Check the correct column name for ground truth labels.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_o0p99gVeJa",
        "outputId": "a77743db-30de-471e-e241-5efbef02f0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.875\n",
            "Accuracy: 0.8805970149253731\n",
            "Precision: 0.9130434782608695\n",
            "Recall: 0.84\n",
            "ROC AUC: 0.8803960396039604\n"
          ]
        }
      ]
    }
  ]
}